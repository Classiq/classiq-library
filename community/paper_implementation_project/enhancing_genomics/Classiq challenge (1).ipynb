{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68614520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pennylane in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (0.38.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: pennylane-lightning>=0.38 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (0.38.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (23.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (2.8.4)\n",
      "Requirement already satisfied: cachetools in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (5.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (4.12.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (1.13.1)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (0.15.1)\n",
      "Requirement already satisfied: autoray>=0.6.11 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (0.7.0)\n",
      "Requirement already satisfied: toml in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: autograd in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pennylane) (1.7.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from requests->pennylane) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from requests->pennylane) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from requests->pennylane) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\swati saraswathi.s.j\\anaconda3\\lib\\site-packages (from requests->pennylane) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c68e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3e821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/SWATI SARASWATHI.S.J/Downloads/GDSC2-dataset.csv')\n",
    "\n",
    "# Extract features and target\n",
    "X = df[['MIN_CONC', 'MAX_CONC', 'LN_IC50', 'AUC', 'RMSE']].values\n",
    "y = df['Z_SCORE'].values > 0  # Binary classification based on Z-score\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Set up a PennyLane device\n",
    "n_qubits = X_train.shape[1]  # One qubit per feature\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c04eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a quantum circuit for data encoding\n",
    "@qml.qnode(dev)\n",
    "def quantum_circuit(x):\n",
    "    # Encode features\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(x[i], wires=i)\n",
    "    \n",
    "    # Create entanglement\n",
    "    for i in range(n_qubits-1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    qml.CNOT(wires=[n_qubits-1, 0])  # Close the loop\n",
    "    \n",
    "    # Second encoding layer\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(x[i], wires=i)\n",
    "        \n",
    "    # Return the quantum state\n",
    "    return qml.state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1048cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantum kernel function\n",
    "def quantum_kernel(x1, x2):\n",
    "    state1 = quantum_circuit(x1)\n",
    "    state2 = quantum_circuit(x2)\n",
    "    inner_product = np.vdot(state1, state2)\n",
    "    # Extract scalar value if inner_product is an array\n",
    "    if hasattr(inner_product, 'shape') and inner_product.shape:\n",
    "        inner_product = inner_product.item()  # Convert to scalar\n",
    "    return np.float32(np.abs(inner_product)**2)\n",
    "\n",
    "class OnTheFlyQuantumSVM(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    SVM classifier using on-the-fly quantum kernel computation\n",
    "    instead of precomputing the full kernel matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1.0, max_iter=50, tol=1e-3):\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.support_vectors_ = None\n",
    "        self.dual_coef_ = None\n",
    "        self.classes_ = None\n",
    "        self.intercept_ = None\n",
    "        self._X_train = None\n",
    "        \n",
    "    def _compute_kernel_row(self, x, X_support):\n",
    "        \"\"\"Compute kernel values between x and all support vectors\"\"\"\n",
    "        kernel_row = np.zeros(len(X_support), dtype=np.float32)\n",
    "        for i, sv in enumerate(X_support):\n",
    "            kernel_row[i] = quantum_kernel(x, sv)\n",
    "        return kernel_row\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the SVM model using custom kernel\"\"\"\n",
    "        print(\"Fitting Quantum SVM with on-the-fly kernel calculation...\")\n",
    "        self.classes_ = np.unique(y)\n",
    "        self._X_train = X\n",
    "        \n",
    "        # Step 1: Use LinearSVC to get an initial set of support vectors\n",
    "        from sklearn.svm import LinearSVC\n",
    "        print(\"Identifying potential support vectors...\")\n",
    "        linear_svc = LinearSVC(C=self.C)\n",
    "        linear_svc.fit(X, y)\n",
    "        \n",
    "        # Step 2: Select a reasonable subset of samples likely to be support vectors\n",
    "        print(\"Selecting subset of potential support vectors...\")\n",
    "        distances = np.abs(linear_svc.decision_function(X))\n",
    "        max_subset_size = min(300, len(X))  # Limit subset size\n",
    "        closest_idx = np.argsort(distances)[:max_subset_size]  # Take points closest to the margin\n",
    "        X_subset = X[closest_idx]\n",
    "        y_subset = y[closest_idx]\n",
    "        \n",
    "        # Step 3: Compute kernel matrix just for this subset\n",
    "        print(f\"Computing kernel matrix for subset of {len(X_subset)} samples...\")\n",
    "        K_subset = np.zeros((len(X_subset), len(X_subset)), dtype=np.float32)\n",
    "        for i, x1 in enumerate(X_subset):\n",
    "            for j, x2 in enumerate(X_subset):\n",
    "                K_subset[i, j] = quantum_kernel(x1, x2)\n",
    "        \n",
    "        # Step 4: Train SVC on this subset with precomputed kernel\n",
    "        print(\"Training SVM on subset with precomputed kernel...\")\n",
    "        subset_svm = SVC(C=self.C, kernel='precomputed', max_iter=self.max_iter, tol=self.tol)\n",
    "        subset_svm.fit(K_subset, y_subset)\n",
    "        \n",
    "        # Step 5: Extract support vectors from the subset\n",
    "        sv_indices_in_subset = subset_svm.support_\n",
    "        self.support_vectors_ = X_subset[sv_indices_in_subset]\n",
    "        self.dual_coef_ = subset_svm.dual_coef_\n",
    "        self.intercept_ = subset_svm.intercept_\n",
    "        \n",
    "        print(f\"Model trained with {len(self.support_vectors_)} support vectors\")\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Compute decision function values for samples in X\"\"\"\n",
    "        if self.support_vectors_ is None:\n",
    "            raise Exception(\"Model not fitted yet\")\n",
    "        \n",
    "        print(f\"Computing decision function for {len(X)} samples...\")\n",
    "        decision_values = np.zeros(len(X))\n",
    "        \n",
    "        intercept = self.intercept_.item() if hasattr(self.intercept_, 'item') else self.intercept_\n",
    "        \n",
    "        # For each test sample\n",
    "        for i, x in enumerate(X):\n",
    "            # Compute kernel values between x and all support vectors on-the-fly\n",
    "            kernel_row = self._compute_kernel_row(x, self.support_vectors_)\n",
    "            \n",
    "            # Decision function value = sum(alpha_i * y_i * K(x_i, x)) + b\n",
    "            decision_values[i] = np.sum(self.dual_coef_ * kernel_row) + intercept\n",
    "            \n",
    "        return decision_values\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for samples in X\"\"\"\n",
    "        decision = self.decision_function(X)\n",
    "        if len(self.classes_) == 2:\n",
    "            return np.where(decision > 0, self.classes_[1], self.classes_[0])\n",
    "        else:\n",
    "            raise NotImplementedError(\"Multi-class not implemented yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d252e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training quantum SVM with on-the-fly kernel calculation...\n",
      "Fitting Quantum SVM with on-the-fly kernel calculation...\n",
      "Identifying potential support vectors...\n",
      "Selecting subset of potential support vectors...\n",
      "Computing kernel matrix for subset of 300 samples...\n",
      "Training SVM on subset with precomputed kernel...\n",
      "Model trained with 100 support vectors\n",
      "Computing decision function for 60509 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SWATI SARASWATHI.S.J\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum SVM Results:\n",
      "Accuracy: 0.4882\n",
      "Precision: 0.4903\n",
      "Recall: 0.4030\n",
      "F1 Score: 0.4424\n"
     ]
    }
   ],
   "source": [
    "print(\"Training quantum SVM with on-the-fly kernel calculation...\")\n",
    "qsvm_on_the_fly = OnTheFlyQuantumSVM(C=1.0)\n",
    "qsvm_on_the_fly.fit(X_train, y_train)\n",
    "y_pred_quantum = qsvm_on_the_fly.predict(X_test)\n",
    "\n",
    "# Evaluate quantum SVM\n",
    "q_accuracy = accuracy_score(y_test, y_pred_quantum)\n",
    "q_precision = precision_score(y_test, y_pred_quantum)\n",
    "q_recall = recall_score(y_test, y_pred_quantum)\n",
    "q_f1 = f1_score(y_test, y_pred_quantum)\n",
    "\n",
    "print(\"\\nQuantum SVM Results:\")\n",
    "print(f\"Accuracy: {q_accuracy:.4f}\")\n",
    "print(f\"Precision: {q_precision:.4f}\")\n",
    "print(f\"Recall: {q_recall:.4f}\")\n",
    "print(f\"F1 Score: {q_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46eefab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training quantum SVM...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'K_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19812\\3045372254.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training quantum SVM...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mqsvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precomputed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mqsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_pred_quantum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Use precomputed kernel with SVC\n",
    "print(\"Training quantum SVM...\")\n",
    "qsvm = SVC(kernel='precomputed')\n",
    "qsvm.fit(K_train, y_train)\n",
    "y_pred_quantum = qsvm.predict(K_test)\n",
    "\n",
    "# Evaluate quantum SVM\n",
    "q_accuracy = accuracy_score(y_test, y_pred_quantum)\n",
    "q_precision = precision_score(y_test, y_pred_quantum)\n",
    "q_recall = recall_score(y_test, y_pred_quantum)\n",
    "q_f1 = f1_score(y_test, y_pred_quantum)\n",
    "\n",
    "print(\"\\nQuantum SVM Results:\")\n",
    "print(f\"Accuracy: {q_accuracy:.4f}\")\n",
    "print(f\"Precision: {q_precision:.4f}\")\n",
    "print(f\"Recall: {q_recall:.4f}\")\n",
    "print(f\"F1 Score: {q_f1:.4f}\")\n",
    "\n",
    "# Compare with classical SVM\n",
    "print(\"\\nTraining classical SVM...\")\n",
    "classical_svm = SVC(kernel='rbf')\n",
    "classical_svm.fit(X_train, y_train)\n",
    "y_pred_classical = classical_svm.predict(X_test)\n",
    "\n",
    "# Calculate classical performance\n",
    "c_accuracy = accuracy_score(y_test, y_pred_classical)\n",
    "c_precision = precision_score(y_test, y_pred_classical)\n",
    "c_recall = recall_score(y_test, y_pred_classical)\n",
    "c_f1 = f1_score(y_test, y_pred_classical)\n",
    "\n",
    "print(\"\\nClassical SVM Results:\")\n",
    "print(f\"Accuracy: {c_accuracy:.4f}\")\n",
    "print(f\"Precision: {c_precision:.4f}\")\n",
    "print(f\"Recall: {c_recall:.4f}\")\n",
    "print(f\"F1 Score: {c_f1:.4f}\")\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Quantum SVM confusion matrix\n",
    "q_cm = confusion_matrix(y_test, y_pred_quantum)\n",
    "sns.heatmap(q_cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "ax1.set_xlabel('Predicted Labels')\n",
    "ax1.set_ylabel('True Labels')\n",
    "ax1.set_title('Quantum SVM Confusion Matrix')\n",
    "\n",
    "# Classical SVM confusion matrix\n",
    "c_cm = confusion_matrix(y_test, y_pred_classical)\n",
    "sns.heatmap(c_cm, annot=True, fmt='d', cmap='Blues', ax=ax2)\n",
    "ax2.set_xlabel('Predicted Labels')\n",
    "ax2.set_ylabel('True Labels')\n",
    "ax2.set_title('Classical SVM Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance metrics\n",
    "metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Quantum SVM': [q_accuracy, q_precision, q_recall, q_f1],\n",
    "    'Classical SVM': [c_accuracy, c_precision, c_recall, c_f1]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics_melted = pd.melt(metrics, id_vars=['Metric'], var_name='Model', value_name='Score')\n",
    "sns.barplot(x='Metric', y='Score', hue='Model', data=metrics_melted)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Performance Comparison: Quantum vs Classical SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_names = ['MIN_CONC', 'MAX_CONC', 'LN_IC50', 'AUC', 'RMSE']\n",
    "\n",
    "# Test each feature's contribution by computing kernel with only that feature\n",
    "feature_importance = []\n",
    "for i in range(len(feature_names)):\n",
    "    # Create mask where only one feature is active\n",
    "    mask = np.zeros(n_qubits, dtype=bool)\n",
    "    mask[i] = True\n",
    "    \n",
    "    # Compute kernels with just this feature\n",
    "    X_train_masked = X_train.copy()\n",
    "    X_train_masked[:, ~mask] = 0\n",
    "    X_test_masked = X_test.copy()\n",
    "    X_test_masked[:, ~mask] = 0\n",
    "    \n",
    "    K_train_single = kernel_matrix(X_train_masked, X_train_masked)\n",
    "    K_test_single = kernel_matrix(X_test_masked, X_train_masked)\n",
    "    \n",
    "    # Train and evaluate model with just this feature\n",
    "    qsvm_single = SVC(kernel='precomputed')\n",
    "    qsvm_single.fit(K_train_single, y_train)\n",
    "    y_pred_single = qsvm_single.predict(K_test_single)\n",
    "    \n",
    "    # Calculate accuracy with just this feature\n",
    "    acc_single = accuracy_score(y_test, y_pred_single)\n",
    "    feature_importance.append(acc_single)\n",
    "\n",
    "# Normalize feature importances\n",
    "feature_importance = np.array(feature_importance)\n",
    "feature_importance = feature_importance / np.sum(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_names, y=feature_importance)\n",
    "plt.title('Feature Importance in Quantum Kernel Classification')\n",
    "plt.ylabel('Normalized Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
