{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b64d66-c3e4-4da8-9736-b05bf9a32409",
   "metadata": {},
   "source": [
    "# The Project\n",
    "- QNN for XOR Problem:\n",
    "\n",
    "  Classiq has an available dataset for training PQC to imitate the XOR gate, similar to how we trained a U-gate to act as a NOT gate. Design a QNN to solve the XOR    problem. Read more on the dataset here.\n",
    "\n",
    "\n",
    "## Setting The Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45633e16-7f1d-4e4f-9346-5524091ed072",
   "metadata": {},
   "source": [
    "When running from Google Colab, we need to install Classiq's SDK and authenticate the remote device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "161ccbd8-538b-4589-a168-e981b49c7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install classiq numpy torchvision torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffbfa1-4e29-4896-84a4-cb38592ca748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classiq\n",
    "# classiq.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6620f-a42c-44ac-89d7-67a2a259f975",
   "metadata": {},
   "source": [
    "# Step 1 - Create our `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ba942-3e8f-4eab-88b7-1638fb26f977",
   "metadata": {
    "id": "dae15b1c-0d3f-4807-ae48-edfba8425962"
   },
   "source": [
    "## Step 1.1 - Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d973e3d-b381-4607-80c1-f669e256e4f7",
   "metadata": {
    "id": "5105b43a-340e-4f79-8d54-f6e898ba415c"
   },
   "source": [
    "Our quantum model will be defined and synthesized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d644402d-4f61-41b6-8427-b45d0c5df1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the following data: tensor([[0.0000],\n",
      "        [3.1416]])\n",
      "with the following labels: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# XORゲートのデータセット\n",
    "from torch.utils.data import DataLoader\n",
    "from classiq.applications.qnn.datasets import (\n",
    "    DatasetNot,\n",
    "    state_to_weights,\n",
    "    state_to_label,\n",
    ")\n",
    "from torchvision.transforms import Lambda\n",
    "NUM_QUBITS = 2\n",
    "\n",
    "DATASET_NOT = DatasetNot(\n",
    "    3, transform=Lambda(state_to_weights), target_transform=Lambda(state_to_label)\n",
    ")\n",
    "\n",
    "DATALOADER_NOT = DataLoader(DATASET_NOT, batch_size=2, shuffle=True)\n",
    "\n",
    "for data, label in DATALOADER_NOT:\n",
    "    print(f\"Training the following data: {data}\")\n",
    "    print(f\"with the following labels: {label}\")\n",
    "\n",
    "data_loader=DATALOADER_NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b015f2a7-4641-4fc8-b6d1-8e0b8d2b751c",
   "metadata": {
    "id": "dae15b1c-0d3f-4807-ae48-edfba8425962"
   },
   "source": [
    "## Step 1.2 - Create our parametric quantum program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de5a77-06b2-40c3-97cb-07352de1bc7c",
   "metadata": {},
   "source": [
    "Our quantum model will be defined and synthesized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fb04f41e-0016-4cd3-a798-9a36321a49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classiq import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 量子プログラムの作成\n",
    "@qfunc\n",
    "def encoding(input_0: CReal, input_1: CReal, q: QArray[QBit]) -> None:\n",
    "    RY(theta=input_0, target=q[0])\n",
    "    RY(theta=input_1, target=q[1])\n",
    "\n",
    "@qfunc\n",
    "def entangle(q: QArray[QBit]) -> None:\n",
    "    CX(control=q[0], target=q[1])\n",
    "\n",
    "@qfunc\n",
    "def mixing(weight_0: CReal, weight_1: CReal, weight_2: CReal, q: QArray[QBit]) -> None:\n",
    "    RX(theta=weight_0, target=q[0])\n",
    "    RX(theta=weight_1, target=q[1])\n",
    "    CRX(theta=weight_2, control=q[0], target=q[1])\n",
    "\n",
    "@qfunc\n",
    "def main(input_0: CReal, input_1: CReal, weight_0: CReal, weight_1: CReal, weight_2: CReal, weight_3: CReal, weight_4: CReal, weight_5: CReal, res: Output[QArray[QBit]]) -> None:\n",
    "    allocate(2, res)\n",
    "    encoding(input_0, input_1, res)\n",
    "    entangle(res)\n",
    "    mixing(weight_0, weight_1, weight_2, res)\n",
    "    entangle(res)\n",
    "    mixing(weight_3, weight_4, weight_5, res)\n",
    "\n",
    "model = create_model(main)\n",
    "quantum_program = synthesize(model)\n",
    "\n",
    "\n",
    "#show(quantum_program)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615654e-fed1-4bfd-bf9d-318557de79ad",
   "metadata": {
    "id": "bef15105-d942-45a6-a615-7b5458241703"
   },
   "source": [
    "## Step 1.3 - Create the Execution and Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10a9b0-d994-4d67-a071-157898793c2e",
   "metadata": {
    "id": "69875135-2a3d-4d8a-91df-ee501f01eac2"
   },
   "source": [
    "The following example defines a function that takes in a parametric quantum program plus parameters, executes the program, and returns the result. Notes:\n",
    "\n",
    "1. The code can be executed on a physical computer or on a simulator. In any case, implement the execution using `execute_qnn`.\n",
    "2. Post-process the result of the execution to obtain a single number (`float`) and a single dimension `Tensor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0ec5e0af-a44f-44c4-a7af-7c256858364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classiq.applications.qnn.types import (\n",
    "    MultipleArguments,\n",
    "    SavedResult,\n",
    "    ResultsCollection,\n",
    ")\n",
    "\n",
    "from classiq.execution import execute_qnn\n",
    "from classiq.synthesis import SerializedQuantumProgram\n",
    "\n",
    "from classiq.applications.qnn.datasets import DATALOADER_NOT\n",
    "\n",
    "\n",
    "# 実行およびポストプロセス関数の作成\n",
    "def execute(quantum_program: SerializedQuantumProgram, arguments: MultipleArguments) -> ResultsCollection:\n",
    "    return execute_qnn(quantum_program, arguments)\n",
    "\n",
    "def post_process(result: SavedResult) -> torch.Tensor:\n",
    "    counts = result.value.counts\n",
    "    p_zero = float(counts.get(\"0\", 0.0) / sum(counts.values()))\n",
    "    return torch.tensor(p_zero)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69934d9a-1245-4739-b267-d8eef8489f8a",
   "metadata": {
    "id": "aa6a64b5-bdff-4e66-b16c-6ede1d69877d"
   },
   "source": [
    "## Step 1.4 - Create a network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b92e8-a8f0-411a-9831-2398599adb84",
   "metadata": {
    "id": "1937b4d5-abfa-40bd-b26e-32c93936be18"
   },
   "source": [
    "Now we're going to define a network, just like any other PyTorch network, only that this time, we will have only 1 layer, and it will be a quantum layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b11021d4-bc80-4421-a8f3-e635b0a6fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# ネットワークの作成\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.qlayer = QLayer(\n",
    "            quantum_program,\n",
    "            execute,\n",
    "            post_process,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.qlayer.weight.data.uniform_(-0.1, 0.1)  # パラメータの初期化\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndimension() == 1:  # データが1次元の場合の処理\n",
    "            input_0 = x.unsqueeze(0)\n",
    "            input_1 = torch.zeros_like(input_0)\n",
    "        elif x.size(1) == 1:  # データが (batch_size, 1) の形状の場合の処理\n",
    "            input_0 = x\n",
    "            input_1 = torch.zeros_like(x)\n",
    "        else:  # データが (batch_size, 2) の形状の場合の処理\n",
    "            input_0 = x[:, 0].unsqueeze(1)\n",
    "            input_1 = x[:, 1].unsqueeze(1)\n",
    "\n",
    "        inputs = torch.cat((input_0, input_1), dim=1)\n",
    "        return self.qlayer(inputs)\n",
    "\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600a642-b863-4eb8-9b8b-6040482b6b4f",
   "metadata": {
    "id": "a94ff1bc-58f5-4743-aa09-0cc77dcfecd6"
   },
   "source": [
    "# Step 2 - Choose a dataset, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3927a-4276-4c1d-b5ed-a343e75a73dc",
   "metadata": {
    "id": "8ac9fb68-bbf5-48c1-ba7a-2af0d9219b74"
   },
   "source": [
    "We will use the DATALOADER_NOT dataset, defined [here](https://docs.classiq.io/latest/reference-manual/built-in-algorithms/qml/qnn/datasets/) as well as [L1Loss](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html) and [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "24ac42c2-31a8-4726-a065-1f88b7be3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classiq.applications.qnn.datasets import DATALOADER_NOT\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "        \n",
    "\n",
    "# 損失関数とオプティマイザの定義\n",
    "loss_func = nn.BCELoss()  # バイナリクロスエントロピー損失関数を使用\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)  # AdamWオプティマイザを使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa079e-5edd-40a6-ab24-5acb891da094",
   "metadata": {
    "id": "b0087ab6-addd-41ac-b609-f60b0b4591cd"
   },
   "source": [
    "# Step 3 - Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca05190d-dde4-4f33-8389-5a85aa70ca23",
   "metadata": {
    "id": "ae072cf7-431f-4583-b5c7-a21be4ef56f2"
   },
   "source": [
    "For the training process, we will use a loop similar to [the one recommended by PyTorch](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#update-the-weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "26b387e2-75d1-49b0-800e-9f87586d5c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 1/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 2/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 3/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 4/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 5/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 6/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 7/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 8/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 9/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 10/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 11/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 12/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 13/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 14/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 15/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 16/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 17/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 18/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 19/20, Loss: 50.0\n",
      "Grad for qlayer.weight: 0.0\n",
      "Gradient for qlayer.weight is zero.\n",
      "Epoch 20/20, Loss: 50.0\n",
      "Trained model saved to trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# 学習およびテストの準備\n",
    "def train(model, data_loader, loss_func, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data, label in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            label = label.view(-1)  # ラベルの形状を修正\n",
    "            loss = loss_func(output, label)\n",
    "            loss.backward()\n",
    "\n",
    "            # 勾配チェックを追加して問題を診断\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    print(f'Grad for {name}: {param.grad.norm().item()}')\n",
    "                else:\n",
    "                    print(f'No grad for {name}')\n",
    "                if param.grad is not None and torch.all(param.grad == 0):\n",
    "                    print(f'Gradient for {name} is zero.')\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data_loader)}')\n",
    "\n",
    "    # 学習後のモデルを保存\n",
    "    torch.save(model.state_dict(), './trained_model.pth')\n",
    "    print(\"Trained model saved to trained_model.pth\")\n",
    "train(model, data_loader, loss_func, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79f438-539d-4412-a839-45c0cb29b4a9",
   "metadata": {
    "id": "61fa4f83-8bd2-4290-9ca4-f6c5c1ca0e32"
   },
   "source": [
    "# Step 4 - Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce1b93-7895-4bcd-95dd-330c0ff8669b",
   "metadata": {
    "id": "7533b162-6214-4606-9e66-ec3332a2f446"
   },
   "source": [
    "Lastly, we will test our network accuracy, using [the following answer](https://stackoverflow.com/questions/52176178/pytorch-model-accuracy-test#answer-64838681)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "34872f7b-45ab-4d65-ba16-8176c8d7807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.0%\n",
      "Data: tensor([[3.1416],\n",
      "        [0.0000]]), Label: tensor([1., 0.]), Output: tensor([0., 0.], grad_fn=<QLayerFunctionBackward>), Loss: 50.0\n"
     ]
    }
   ],
   "source": [
    "# テスト関数\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            output = model(data)\n",
    "            label = label.view(-1)  # ラベルの形状を修正\n",
    "            predicted = (output > 0.5).float()\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total}%')\n",
    "\n",
    "test(model, DATALOADER_NOT)\n",
    "\n",
    "# デバッグ情報を追加して再度確認\n",
    "for data, label in DATALOADER_NOT:\n",
    "    model = Net()\n",
    "    output = model(data)\n",
    "    label = label.view(-1)  # ラベルの形状を修正\n",
    "    loss = loss_func(output, label)\n",
    "    print(f\"Data: {data}, Label: {label}, Output: {output}, Loss: {loss.item()}\")\n",
    "    break  # 最初のバッチのみを確認\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eae25d-cccc-412b-b968-1af7574794a3",
   "metadata": {},
   "source": [
    "## reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8ce58b0f-714e-41b4-8e95-7b0be6080a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and set to evaluation mode.\n",
      "Accuracy: 50.0%\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('./trained_model.pth'))\n",
    "model.eval()\n",
    "print(\"Model loaded successfully and set to evaluation mode.\")\n",
    "\n",
    "# テストの実行\n",
    "test(model, DATALOADER_NOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feac5cd-8b05-4c69-880d-350ec4ecb942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
